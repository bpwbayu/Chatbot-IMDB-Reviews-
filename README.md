<<<<<<< HEAD
# Predict-Medical-Cost

ğŸ©º Medical Cost Prediction
This project aims to predict medical insurance costs based on personal factors. It uses
regression models to identify the factors that most influence an individual's insurance costs.
The models used are Linear Regression, Random Forest, and K-Neighbors Regressor.]

ğŸ“Dataset
Source: Kaggle - Medical Cost Personal Dataset
This dataset contains 1,338 individual data points with seven input features, including age,
sex, BMI, children, smoker, region, and charges.
âš™ Tools
â— Python (Pandas, NumPy, scikit-learn, Matplotlib, Seaborn)
â— Jupyter Notebook/VS Code
ğŸ¯ Purpose of Analysis
â— Predicting an individual's medical insurance costs based on lifestyle and
demographic data.
â— Identifying the features that most influence insurance costs.
â— Comparing the performance of different regression models.
ğŸ” Steps
1. Data Loading & Exploratory Data Analysis (EDA)
â— Reading datasets using Pandas
â— Checking missing values and descriptive statistics
â— Analysing relationships between variables with heatmaps and scatter plots
2. Feature Engineering
â— Create additional features, such as:
â—‹ BMI_Category â†’ categorises BMI values into Underweight, Normal,
Overweight, Obese
â—‹ Age_Group â†’ grouping ages into the categories Young, Adult, Senior
â—‹ Smoker_BMI_Interaction â†’ combined effect of smoking and high BMI
on insurance costs
â— One-hot encoding for categorical features
3. Data Splitting & Scaling
â— Split the data into train (80%) and test (20%)
â— Normalise numerical features using StandardScaler
4. Modeling
Model used:
â— Linear Regression
â— Random Forest Regressor
â— K-Neighbors Regressor
5. Evaluation
â— Mean Absolute Error (MAE)
â— Root Mean Squared Error (RMSE)
â— RÂ² Score
ğŸ“Š Visualization
â— Linear Regression showed the best performance with the highest RÂ² value and the
smallest error.
â— The most influential features were smoker, age, and BMI.
â— The scatter plot showed that smokers with high BMI had significantly higher
insurance costs.
ğŸ§ Insight
1. Smokers incur much higher insurance costs than non-smokers.
2. Older age â†’ higher insurance costs.
3. High BMI â†’ higher insurance costs.
4. Region & number of children â†’ less impact.
5. Combined effects (BMI_smoker & age_smoker) â†’ amplify costs.
6. Among all the models tested, Random Forest performed best in predicting insurance
charges, demonstrating its ability to identify non-linear relationships in the data.
Linear regression showed the highest RÂ² score (0.8869), indicating better overall
suitability and consistency in the data. Therefore, linear regression was selected as
the final model for this project due to its strong balance between readability and
prediction accuracy.
ğŸš€ How to Run
â— Ensure all required packages are installed:
pip install pandas numpy scikit-learn seaborn matplotlib
â— Run the notebook in Jupyter or VS Code:
jupyter notebook Project_MedicalCost.ipynb
=======
# ğŸ¤– Chatbot IMDB Reviews 
The aim is to develop chatbots and machine learning models that can classify film review sentiments from the IMDB dataset and provide appropriate automated responses based on the results of the sentiment analysis.

---
## ğŸ“Dataset
Source: Kaggle - IMDB Dataset of 50K Movie Reviews
- The dataset offers a balanced set of labelled text samples, making it ideal for training and evaluating sentiment analysis models.
---
## âš™ Tools 
- Python (Pandas, NumPy, Scikit-Learn, Re, Joblib,  Matplotlib, Seaborn, NLTK, Streamlit )
- Jupyter Notebook/VS Code 
---
## ğŸ¯ Purpose of Analysis
- Provide prompt and relevant responses to customer inquiries or complaints.
- Identify positive, neutral, and negative sentiments to gauge customer satisfaction and detect potential issues.
- Support data-driven insights for content producers, marketers, and researchers interested in audience sentiment trends.
---
## ğŸ” Steps 
### 1. Data Loading & Exploratory Data Analysis (EDA)
- Reading datasets using Pandas
- Checking missing values and descriptive statistics
- Examine message length, inbound distribution, number of reviews per date
### 2. Feature Engineering
- Text cleaning and lemmatization
- Create additional features for sentiment scores then convert scores into sentiment labels
- One-hot encoding for additional features
### 3. Data Splitting & Scaling
- Split the data into train (80%) and test (20%)
- The data was split using stratification to maintain balanced proportions of each sentiment label, and the text was then transformed into numerical representations using TF-IDF before being fed into the models.
### 4. Modeling
  Model used:
- Multinomial Naive Bayes
- Logistic Regression
- Random Forest Classifier
### 5. Evaluation
- Classification Report (Precision, Recall, F1-support)
- Confusion Matrix
- Accuracy Score
---
## ğŸ“Š Visualization
- The sentiment distribution shows a balanced dataset between positive and negative reviews, each with roughly equal frequency.
- The text length distribution indicates that most reviews are short to medium-length, with a few very long reviews extending beyond 10,000 characters.
---
## ğŸ§ Insight

The project successfully developed a chatbot integrated with a machine learning model capable of classifying IMDb movie review sentiments accurately. 
Through machine learning, the Logistic Regression model achieved the highest and most consistent performance (accuracy = 0.8975), outperforming Naive Bayes and Random Forest.

---
## ğŸš€ How to Run
- Ensure all required packages are installed:

  ```pip install pandas numpy scikit-learn re joblib matplotlib seaborn nltk streamlit```

- Run the notebook in Jupyter or VS Code:

  ```jupyter notebook Project_ChatbotCustomerSupport.ipynb```

- Run the Streamlit:

  ```streamlit run app.py```
>>>>>>> 12b531168258a6dc4b4c29698e0f0f448d0dadd6
